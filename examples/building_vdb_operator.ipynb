{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Custom Vector Database Operator\n",
    "\n",
    "This tutorial demonstrates how to build a custom Vector Database (VDB) operator for NV-Ingest using the abstract `VDB` class. We implement a complete OpenSearch operator as an example.\n",
    "\n",
    "**Important:** NVIDIA makes no claim about accuracy, performance, or functionality of any vector database except Milvus. If you use a different vector database, it's your responsibility to test and maintain it.\n",
    "\n",
    "## Overview\n",
    "\n",
    "NV-Ingest provides an abstract base class `VDB` located in `client/src/nv_ingest_client/util/vdb/adt_vdb.py` that defines the interface for vector database operations. By inheriting from this class and implementing its abstract methods, you can create custom operators for any vector database.\n",
    "\n",
    "In this tutorial, we build an OpenSearch operator. OpenSearch is an open-source, distributed search and analytics engine derived from Elasticsearch, maintained by the OpenSearch Software Foundation since 2021."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Before implementing your custom VDB operator, you must understand how to interact with your chosen vector database. For OpenSearch, you should be familiar with:\n",
    "\n",
    "### Essential Knowledge Requirements\n",
    "\n",
    "1. **Python Client Integration**: How to interact with the database using Python\n",
    "2. **Database Deployment**: How to run and manage the database instance\n",
    "3. **Connection Management**: How to establish and maintain database connections\n",
    "4. **Index Operations**: How to create, manage, and configure indexes\n",
    "5. **Data Ingestion**: How to load documents and records into indexes\n",
    "6. **Query Operations**: How to retrieve relevant documents using vector similarity search\n",
    "\n",
    "For OpenSearch, comprehensive documentation is available at [https://docs.opensearch.org/docs/latest/](https://docs.opensearch.org/docs/latest/).\n",
    "\n",
    "**Note**: This tutorial assumes you have already configured and deployed OpenSearch in your environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Database Configuration\n",
    "\n",
    "### Docker Compose Setup\n",
    "\n",
    "To integrate OpenSearch with the NV-Ingest ecosystem, add the following configuration to your `docker-compose.yml` file:\n",
    "\n",
    "```yaml\n",
    "opensearch:\n",
    "  image: opensearchproject/opensearch:3.1.0\n",
    "  ports:\n",
    "    - \"9200:9200\"\n",
    "    - \"9300:9300\"\n",
    "  environment:\n",
    "    - cluster.name=opensearch-cluster\n",
    "    - node.name=opensearch-node\n",
    "    - discovery.type=single-node\n",
    "    - bootstrap.memory_lock=true\n",
    "    - \"OPENSEARCH_JAVA_OPTS=-Xms512m -Xmx512m -XX:MaxDirectMemorySize=10g\"\n",
    "    - OPENSEARCH_INITIAL_ADMIN_PASSWORD=\"myStrongPassword123@456\"\n",
    "    - DISABLE_SECURITY_PLUGIN=true\n",
    "  volumes:\n",
    "    - ./.volumes/opensearch:/usr/share/opensearch/data\n",
    "  healthcheck:\n",
    "    test: [ \"CMD\", \"curl\", \"-f\", \"http://localhost:9200\" ]\n",
    "    interval: 30s\n",
    "    timeout: 20s\n",
    "    retries: 3\n",
    "  profiles:\n",
    "    - retrieval\n",
    "\n",
    "opensearch-dashboards:\n",
    "  image: opensearchproject/opensearch-dashboards:latest\n",
    "  container_name: opensearch-dashboards\n",
    "  ports:\n",
    "    - \"5601:5601\"\n",
    "  environment:\n",
    "    OPENSEARCH_HOSTS: '[\"http://opensearch:9200\"]'\n",
    "    DISABLE_SECURITY_DASHBOARDS_PLUGIN: 'true'\n",
    "  depends_on:\n",
    "    - opensearch\n",
    "```\n",
    "\n",
    "### Starting the Services\n",
    "\n",
    "After adding the configuration, start the OpenSearch services using:\n",
    "\n",
    "```bash\n",
    "docker compose up -d\n",
    "```\n",
    "\n",
    "This will launch both OpenSearch and OpenSearch Dashboards containers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Understanding the VDB Abstract Class\n",
    "\n",
    "The `VDB` abstract class provides a lightweight interface that defines the essential operations for vector database integration. It contains the following abstract methods:\n",
    "\n",
    "- `__init__(**kwargs)`: Initialize the operator with configuration parameters\n",
    "- `create_index(**kwargs)`: Create or configure database indexes\n",
    "- `write_to_index(records: list, **kwargs)`: Write records to the database\n",
    "- `retrieval(queries: list, **kwargs)`: Perform similarity search queries\n",
    "- `run(records)`: Main entry point for the NV-Ingest pipeline\n",
    "- `reindex(records: list, **kwargs)`: Rebuild indexes with new data (optional)\n",
    "\n",
    "The design philosophy emphasizes flexibility - each method accepts `**kwargs` to allow developers to implement custom parameter handling according to their specific requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Creating the Custom Operator Class\n",
    "\n",
    "Begin by creating a new class that inherits from the `VDB` abstract class. This establishes the foundation for your custom operator:\n",
    "\n",
    "```python\n",
    "from nv_ingest_client.util.vdb.adt_vdb import VDB\n",
    "\n",
    "class OpenSearch(VDB):\n",
    "    def __init__(self, **kwargs):\n",
    "        pass\n",
    "\n",
    "    def create_index(self, **kwargs):\n",
    "        pass\n",
    "\n",
    "    def write_to_index(self, records: list, **kwargs):\n",
    "        pass\n",
    "\n",
    "    def retrieval(self, queries: list, **kwargs):\n",
    "        pass\n",
    "\n",
    "    def reindex(self, records: list, **kwargs):\n",
    "        pass\n",
    "\n",
    "    def run(self, records):\n",
    "        pass\n",
    "```\n",
    "\n",
    "This skeleton class provides the structure for implementing each required method. The `run` method serves as the primary entry point for NV-Ingest integration, but we will implement it last after completing the core functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from nv_ingest_client.util.vdb.adt_vdb import VDB\n",
    "\n",
    "\n",
    "\n",
    "class OpenSearch(VDB):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        pass\n",
    "\n",
    "    def create_index(self, **kwargs):\n",
    "        pass\n",
    "\n",
    "    def write_to_index(self, records: list, **kwargs):\n",
    "        pass\n",
    "\n",
    "    def retrieval(self, queries: list, **kwargs):\n",
    "        pass\n",
    "\n",
    "    def reindex(self, records: list, **kwargs):\n",
    "        pass\n",
    "\n",
    "    def run(self, records):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Implementing the Constructor\n",
    "\n",
    "The `__init__` method is responsible for:\n",
    "1. Extracting and storing configuration parameters\n",
    "2. Setting default values for optional parameters\n",
    "3. Initializing the database client connection\n",
    "\n",
    "### Configuration Parameters\n",
    "\n",
    "Define the parameters your operator will accept, including connection details, index configuration, and content type filters:\n",
    "\n",
    "```python\n",
    "def __init__(self, **kwargs):\n",
    "    # Connection parameters\n",
    "    self.host = kwargs.get(\"host\", \"localhost\")\n",
    "    self.port = kwargs.get(\"port\", 9200)\n",
    "    self.username = kwargs.get(\"username\", \"admin\")\n",
    "    self.password = kwargs.get(\"password\", \"admin\")\n",
    "    self.use_ssl = kwargs.get(\"use_ssl\", False)\n",
    "    self.verify_certs = kwargs.get(\"verify_certs\", False)\n",
    "    self.http_compress = kwargs.get(\"http_compress\", False)\n",
    "    \n",
    "    # Index configuration\n",
    "    self.dense_dim = kwargs.get(\"dense_dim\", 2048)\n",
    "    self.index_name = kwargs.get(\"index_name\", \"nv_ingest_test\")\n",
    "    \n",
    "    # Content type filters\n",
    "    self.enable_text = kwargs.get(\"enable_text\", True)\n",
    "    self.enable_charts = kwargs.get(\"enable_charts\", True)\n",
    "    self.enable_tables = kwargs.get(\"enable_tables\", True)\n",
    "    self.enable_images = kwargs.get(\"enable_images\", True)\n",
    "    self.enable_infographics = kwargs.get(\"enable_infographics\", True)\n",
    "    self.enable_audio = kwargs.get(\"enable_audio\", True)\n",
    "    \n",
    "    # Initialize parent class\n",
    "    super().__init__(**kwargs)\n",
    "    \n",
    "    # Initialize OpenSearch client\n",
    "    self.client = opensearch.OpenSearch(\n",
    "        hosts=[{\"host\": self.host, \"port\": self.port}],\n",
    "        http_compress=self.http_compress,\n",
    "        use_ssl=self.use_ssl,\n",
    "        verify_certs=self.verify_certs,\n",
    "    )\n",
    "```\n",
    "\n",
    "This implementation provides a robust foundation with sensible defaults while allowing customization through keyword arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   def __init__(self, **kwargs):\n",
    "        self.host = kwargs.get(\"host\", \"localhost\")\n",
    "        self.port = kwargs.get(\"port\", 9200)\n",
    "        self.username = kwargs.get(\"username\", \"admin\")\n",
    "        self.password = kwargs.get(\"password\", \"admin\")\n",
    "        self.use_ssl = kwargs.get(\"use_ssl\", False)\n",
    "        self.verify_certs = kwargs.get(\"verify_certs\", False)\n",
    "        self.http_compress = kwargs.get(\"http_compress\", False)\n",
    "        self.dense_dim = kwargs.get(\"dense_dim\", 2048)\n",
    "        self.index_name = kwargs.get(\"index_name\", \"nv_ingest_test\")\n",
    "        self.enable_text = kwargs.get(\"enable_text\", True)\n",
    "        self.enable_charts = kwargs.get(\"enable_charts\", True)\n",
    "        self.enable_tables = kwargs.get(\"enable_tables\", True)\n",
    "        self.enable_images = kwargs.get(\"enable_images\", True)\n",
    "        self.enable_infographics = kwargs.get(\"enable_infographics\", True)\n",
    "        self.enable_audio = kwargs.get(\"enable_audio\", True)\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.client = opensearch.OpenSearch(\n",
    "            hosts=[{\"host\": self.host, \"port\": self.port}],\n",
    "            http_compress=self.http_compress,\n",
    "            # http_auth=(self.username, self.password),\n",
    "            use_ssl=self.use_ssl,\n",
    "            verify_certs=self.verify_certs,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Implementing Index Creation\n",
    "\n",
    "The `create_index` method handles the creation and configuration of database indexes. For OpenSearch, this involves setting up a k-NN index optimized for vector similarity search.\n",
    "\n",
    "### Key Implementation Considerations\n",
    "\n",
    "1. **Index Existence Check**: Verify if the index already exists before creation\n",
    "2. **Recreation Logic**: Provide option to recreate indexes when needed\n",
    "3. **Index Configuration**: Define appropriate mappings and settings for vector search\n",
    "\n",
    "```python\n",
    "def create_index(self, **kwargs):\n",
    "    recreate = kwargs.get(\"recreate\", False)\n",
    "    exists = self.client.indices.exists(index=f\"{self.index_name}_dense\")\n",
    "    \n",
    "    # Handle index recreation if requested\n",
    "    if recreate and exists:\n",
    "        self.client.indices.delete(index=f\"{self.index_name}_dense\")\n",
    "        exists = False\n",
    "    \n",
    "    # Create index if it doesn't exist\n",
    "    if not exists:\n",
    "        index_body = {\n",
    "            \"settings\": {\n",
    "                \"index.knn\": True,\n",
    "                \"index.knn.algo_param.ef_search\": 100,\n",
    "            },\n",
    "            \"mappings\": {\n",
    "                \"properties\": {\n",
    "                    \"dense\": {\n",
    "                        \"type\": \"knn_vector\",\n",
    "                        \"dimension\": self.dense_dim,\n",
    "                        \"method\": {\n",
    "                            \"name\": \"hnsw\",\n",
    "                            \"engine\": \"faiss\",\n",
    "                            \"space_type\": \"l2\",\n",
    "                            \"parameters\": {\"m\": 16, \"ef_construction\": 100},\n",
    "                        },\n",
    "                    },\n",
    "                    \"text\": {\"type\": \"text\"},\n",
    "                    \"id\": {\"type\": \"keyword\"},\n",
    "                    \"metadata\": {\"type\": \"object\"},\n",
    "                }\n",
    "            },\n",
    "        }\n",
    "        \n",
    "        self.client.indices.create(index=f\"{self.index_name}_dense\", body=index_body)\n",
    "```\n",
    "\n",
    "This implementation creates a k-NN index with HNSW (Hierarchical Navigable Small World) algorithm for efficient approximate nearest neighbor search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def create_index(self, **kwargs):\n",
    "        recreate = kwargs.get(\"recreate\", False)\n",
    "        exists = self.client.indices.exists(index=f\"{self.index_name}_dense\")\n",
    "        if recreate and exists:\n",
    "            self.client.indices.delete(index=f\"{self.index_name}_dense\")\n",
    "            exists = False\n",
    "        if not exists:\n",
    "            index_body = {\n",
    "                \"settings\": {\n",
    "                    \"index.knn\": True,\n",
    "                    \"index.knn.algo_param.ef_search\": 100,\n",
    "                },\n",
    "                \"mappings\": {\n",
    "                    \"properties\": {\n",
    "                        \"dense\": {\n",
    "                            \"type\": \"knn_vector\",\n",
    "                            \"dimension\": self.dense_dim,\n",
    "                            \"method\": {\n",
    "                                \"name\": \"hnsw\",\n",
    "                                \"engine\": \"faiss\",\n",
    "                                \"space_type\": \"l2\",\n",
    "                                \"parameters\": {\"m\": 16, \"ef_construction\": 100},\n",
    "                            },\n",
    "                        },\n",
    "                        \"text\": {\"type\": \"text\"},\n",
    "                        \"id\": {\"type\": \"keyword\"},\n",
    "                        \"metadata\": {\"type\": \"object\"},\n",
    "                    }\n",
    "                },\n",
    "            }\n",
    "\n",
    "            self.client.indices.create(index=f\"{self.index_name}_dense\", body=index_body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Implementing Data Ingestion\n",
    "\n",
    "The `write_to_index` method processes and stores records in the vector database. This involves:\n",
    "\n",
    "1. **Record Transformation**: Converting NV-Ingest records to database-compatible format\n",
    "2. **Content Filtering**: Applying content type filters based on configuration\n",
    "3. **Data Validation**: Ensuring records contain required fields (embeddings, text)\n",
    "4. **Batch Processing**: Efficiently writing multiple records to the database\n",
    "\n",
    "### Core Implementation\n",
    "\n",
    "```python\n",
    "def write_to_index(self, records: list, **kwargs):\n",
    "    for record_set in records:\n",
    "        for record in record_set:\n",
    "            transform_record = self.transform_record(record)\n",
    "            if transform_record:\n",
    "                self.client.index(index=f\"{self.index_name}_dense\", body=transform_record, id=count)\n",
    "```\n",
    "\n",
    "### Record Transformation Helper\n",
    "\n",
    "The `transform_record` method extracts and validates the necessary data from NV-Ingest records:\n",
    "\n",
    "```python\n",
    "def transform_record(self, record: dict):\n",
    "    text = _pull_text(\n",
    "        record,\n",
    "        self.enable_text,\n",
    "        self.enable_charts,\n",
    "        self.enable_tables,\n",
    "        self.enable_images,\n",
    "        self.enable_infographics,\n",
    "        self.enable_audio,\n",
    "    )\n",
    "    if text:\n",
    "        return {\n",
    "            \"dense\": record[\"metadata\"][\"embedding\"],\n",
    "            \"text\": text,\n",
    "            \"metadata\": record[\"metadata\"][\"content_metadata\"],\n",
    "        }\n",
    "    else:\n",
    "        return None\n",
    "```\n",
    "\n",
    "### Content Extraction and Validation\n",
    "\n",
    "The `_pull_text` function handles content extraction from different document types:\n",
    "\n",
    "```python\n",
    "def _pull_text(\n",
    "    element,\n",
    "    enable_text: bool,\n",
    "    enable_charts: bool,\n",
    "    enable_tables: bool,\n",
    "    enable_images: bool,\n",
    "    enable_infographics: bool,\n",
    "    enable_audio: bool,\n",
    "):\n",
    "    text = None\n",
    "    \n",
    "    # Extract text based on document type and enabled content types\n",
    "    if element[\"document_type\"] == \"text\" and enable_text:\n",
    "        text = element[\"metadata\"][\"content\"]\n",
    "    elif element[\"document_type\"] == \"structured\":\n",
    "        text = element[\"metadata\"][\"table_metadata\"][\"table_content\"]\n",
    "        if element[\"metadata\"][\"content_metadata\"][\"subtype\"] == \"chart\" and not enable_charts:\n",
    "            text = None\n",
    "        elif element[\"metadata\"][\"content_metadata\"][\"subtype\"] == \"table\" and not enable_tables:\n",
    "            text = None\n",
    "        elif element[\"metadata\"][\"content_metadata\"][\"subtype\"] == \"infographic\" and not enable_infographics:\n",
    "            text = None\n",
    "    elif element[\"document_type\"] == \"image\" and enable_images:\n",
    "        text = element[\"metadata\"][\"image_metadata\"][\"caption\"]\n",
    "    elif element[\"document_type\"] == \"audio\" and enable_audio:\n",
    "        text = element[\"metadata\"][\"audio_metadata\"][\"audio_transcript\"]\n",
    "    \n",
    "    # Validate embedding and text requirements\n",
    "    verify_emb = verify_embedding(element)\n",
    "    if not text or not verify_emb:\n",
    "        source_name = element[\"metadata\"][\"source_metadata\"][\"source_name\"]\n",
    "        pg_num = element[\"metadata\"][\"content_metadata\"].get(\"page_number\", None)\n",
    "        doc_type = element[\"document_type\"]\n",
    "        if not verify_emb:\n",
    "            logger.debug(f\"failed to find embedding for entity: {source_name} page: {pg_num} type: {doc_type}\")\n",
    "        if not text:\n",
    "            logger.debug(f\"failed to find text for entity: {source_name} page: {pg_num} type: {doc_type}\")\n",
    "        text = None\n",
    "    \n",
    "    # Handle text length limitations\n",
    "    if text and len(text) > 65535:\n",
    "        logger.warning(\n",
    "            f\"Text is too long, skipping. It is advised to use SplitTask, to make smaller chunk sizes.\"\n",
    "            f\"text_length: {len(text)}, file_name: {element['metadata']['source_metadata'].get('source_name', None)} \"\n",
    "            f\"page_number: {element['metadata']['content_metadata'].get('page_number', None)}\"\n",
    "        )\n",
    "        text = None\n",
    "    \n",
    "    return text\n",
    "```\n",
    "\n",
    "This implementation ensures data quality by validating embeddings, filtering content types, and handling text length limitations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Implementing the Main Entry Point\n",
    "\n",
    "The `run` method serves as the primary interface between NV-Ingest and your custom operator. It orchestrates the index creation and data ingestion processes.\n",
    "\n",
    "### Implementation\n",
    "\n",
    "```python\n",
    "def run(self, records):\n",
    "    self.create_index()\n",
    "    self.write_to_index(records)\n",
    "```\n",
    "\n",
    "This method is called by the NV-Ingest Ingestor class during the ingestion pipeline. For more information on how operators are integrated into NV-Ingest, refer to the [interface implementation](https://github.com/NVIDIA/nv-ingest/blob/release/25.6.2/client/src/nv_ingest_client/client/interface.py#L324).\n",
    "\n",
    "The simplicity of this method belies its importance - it ensures that indexes are properly configured before data ingestion begins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_index(self, records: list, **kwargs):\n",
    "    for record_set in records:\n",
    "        for record in record_set:\n",
    "            transform_record = self.transform_record(record)\n",
    "            if transform_record:\n",
    "                self.client.index(index=f\"{self.index_name}_dense\", body=transform_record, id=count)\n",
    "\n",
    "def transform_record(self, record: dict):\n",
    "    text = _pull_text(\n",
    "        record,\n",
    "        self.enable_text,\n",
    "        self.enable_charts,\n",
    "        self.enable_tables,\n",
    "        self.enable_images,\n",
    "        self.enable_infographics,\n",
    "        self.enable_audio,\n",
    "    )\n",
    "    if text:\n",
    "        return {\n",
    "            \"dense\": record[\"metadata\"][\"embedding\"],\n",
    "            \"text\": text,\n",
    "            \"metadata\": record[\"metadata\"][\"content_metadata\"],\n",
    "        }\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def verify_embedding(element):\n",
    "    if element[\"metadata\"][\"embedding\"] is not None:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def _pull_text(\n",
    "    element,\n",
    "    enable_text: bool,\n",
    "    enable_charts: bool,\n",
    "    enable_tables: bool,\n",
    "    enable_images: bool,\n",
    "    enable_infographics: bool,\n",
    "    enable_audio: bool,\n",
    "):\n",
    "    text = None\n",
    "    if element[\"document_type\"] == \"text\" and enable_text:\n",
    "        text = element[\"metadata\"][\"content\"]\n",
    "    elif element[\"document_type\"] == \"structured\":\n",
    "        text = element[\"metadata\"][\"table_metadata\"][\"table_content\"]\n",
    "        if element[\"metadata\"][\"content_metadata\"][\"subtype\"] == \"chart\" and not enable_charts:\n",
    "            text = None\n",
    "        elif element[\"metadata\"][\"content_metadata\"][\"subtype\"] == \"table\" and not enable_tables:\n",
    "            text = None\n",
    "        elif element[\"metadata\"][\"content_metadata\"][\"subtype\"] == \"infographic\" and not enable_infographics:\n",
    "            text = None\n",
    "    elif element[\"document_type\"] == \"image\" and enable_images:\n",
    "        text = element[\"metadata\"][\"image_metadata\"][\"caption\"]\n",
    "    elif element[\"document_type\"] == \"audio\" and enable_audio:\n",
    "        text = element[\"metadata\"][\"audio_metadata\"][\"audio_transcript\"]\n",
    "    verify_emb = verify_embedding(element)\n",
    "    if not text or not verify_emb:\n",
    "        source_name = element[\"metadata\"][\"source_metadata\"][\"source_name\"]\n",
    "        pg_num = element[\"metadata\"][\"content_metadata\"].get(\"page_number\", None)\n",
    "        doc_type = element[\"document_type\"]\n",
    "        if not verify_emb:\n",
    "            logger.debug(f\"failed to find embedding for entity: {source_name} page: {pg_num} type: {doc_type}\")\n",
    "        if not text:\n",
    "            logger.debug(f\"failed to find text for entity: {source_name} page: {pg_num} type: {doc_type}\")\n",
    "        # if we do find text but no embedding remove anyway\n",
    "        text = None\n",
    "    if text and len(text) > 65535:\n",
    "        logger.warning(\n",
    "            f\"Text is too long, skipping. It is advised to use SplitTask, to make smaller chunk sizes.\"\n",
    "            f\"text_length: {len(text)}, file_name: {element['metadata']['source_metadata'].get('source_name', None)} \"\n",
    "            f\"page_number: {element['metadata']['content_metadata'].get('page_number', None)}\"\n",
    "        )\n",
    "        text = None\n",
    "    return text\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Implementing Vector Search Retrieval\n",
    "\n",
    "The `retrieval` method enables similarity search functionality by:\n",
    "\n",
    "1. **Query Embedding**: Converting text queries to vector embeddings\n",
    "2. **Vector Search**: Performing k-NN search against stored vectors\n",
    "3. **Result Processing**: Formatting and cleaning search results\n",
    "4. **Response Optimization**: Removing unnecessary data from responses\n",
    "\n",
    "### Implementation\n",
    "\n",
    "```python\n",
    "def retrieval(self, queries: list, **kwargs):\n",
    "    client_config = ClientConfigSchema()\n",
    "    index_name = kwargs.get(\"index_name\", f\"{self.index_name}_dense\")\n",
    "    top_k = kwargs.get(\"top_k\", 10)\n",
    "    nvidia_api_key = kwargs.get(\"nvidia_api_key\" or client_config.nvidia_api_key)\n",
    "    embedding_endpoint = kwargs.get(\"embedding_endpoint\", client_config.embedding_nim_endpoint)\n",
    "    model_name = kwargs.get(\"model_name\", client_config.embedding_nim_model_name)\n",
    "    \n",
    "    from llama_index.embeddings.nvidia import NVIDIAEmbedding\n",
    "    \n",
    "    # Initialize embedding model for query vectorization\n",
    "    dense_model = NVIDIAEmbedding(\n",
    "        base_url=embedding_endpoint, \n",
    "        model=model_name, \n",
    "        nvidia_api_key=nvidia_api_key\n",
    "    )\n",
    "    \n",
    "    results = []\n",
    "    for query in queries:\n",
    "        # Generate query embedding\n",
    "        embedding = dense_model.get_query_embedding(query)\n",
    "        \n",
    "        # Construct k-NN query\n",
    "        query_body = {\n",
    "            \"query\": {\n",
    "                \"knn\": {\n",
    "                    \"dense\": {\n",
    "                        \"vector\": embedding,\n",
    "                        \"k\": top_k,\n",
    "                    },\n",
    "                },\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Execute search and process results\n",
    "        response = [\n",
    "            hit[\"_source\"]\n",
    "            for hit in self.client.search(index=f\"{index_name}_dense\", body=query_body)[\"hits\"][\"hits\"]\n",
    "        ]\n",
    "        \n",
    "        # Remove dense embeddings from response to reduce payload size\n",
    "        for res in response:\n",
    "            res.pop(\"dense\")\n",
    "        \n",
    "        results.append(response)\n",
    "    \n",
    "    return results\n",
    "```\n",
    "\n",
    "### Key Features\n",
    "\n",
    "- **Configurable Search Parameters**: Supports custom `top_k` values and index names\n",
    "- **NVIDIA Embedding Integration**: Uses NVIDIA's embedding models for query vectorization\n",
    "- **Result Optimization**: Removes vector embeddings from responses to reduce payload size\n",
    "- **Batch Query Support**: Processes multiple queries efficiently\n",
    "\n",
    "This implementation provides a complete vector search solution that integrates seamlessly with NV-Ingest's retrieval pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    def run(self, records):\n",
    "        self.create_index()\n",
    "        self.write_to_index(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, the `run` method is very simple. It first creates an index using the arguments that the VDB Operator was instantiated with, and then right the records to that index. The only functionality left to define is the retrieval. So the `retrieval` method has one parameter, `queries` which represents the list of queries we want to retrieve results for from the vector database(VDB). So in this function we include all the logic required to submit the queries to the VDB and and then format the responses correctly. In this operator, we ensure that we remove unnecessary elements from the response, the dense embedding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def retrieval(self, queries: list, **kwargs):\n",
    "        client_config = ClientConfigSchema()\n",
    "        index_name = kwargs.get(\"index_name\", f\"{self.index_name}_dense\")\n",
    "        top_k = kwargs.get(\"top_k\", 10)\n",
    "        nvidia_api_key = kwargs.get(\"nvidia_api_key\" or client_config.nvidia_api_key)\n",
    "        # required for NVIDIAEmbedding call if the endpoint is Nvidia build api.\n",
    "        embedding_endpoint = kwargs.get(\"embedding_endpoint\", client_config.embedding_nim_endpoint)\n",
    "        model_name = kwargs.get(\"model_name\", client_config.embedding_nim_model_name)\n",
    "        from llama_index.embeddings.nvidia import NVIDIAEmbedding\n",
    "\n",
    "        dense_model = NVIDIAEmbedding(base_url=embedding_endpoint, model=model_name, nvidia_api_key=nvidia_api_key)\n",
    "        results = []\n",
    "        for query in queries:\n",
    "            embedding = dense_model.get_query_embedding(query)\n",
    "\n",
    "            query_body = {\n",
    "                \"query\": {\n",
    "                    \"knn\": {\n",
    "                        \"dense\": {\n",
    "                            \"vector\": embedding,\n",
    "                            \"k\": top_k,\n",
    "                        },\n",
    "                    },\n",
    "                }\n",
    "            }\n",
    "            response = [\n",
    "                hit[\"_source\"]\n",
    "                for hit in self.client.search(index=f\"{index_name}_dense\", body=query_body)[\"hits\"][\"hits\"]\n",
    "            ]\n",
    "            for res in response:\n",
    "                res.pop(\"dense\")\n",
    "            results.append(response)\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Congratulations! You have successfully learned how to create a custom Vector Database operator for NV-Ingest using the abstract `VDB` class. This tutorial has demonstrated the complete implementation of an OpenSearch operator, showcasing all the essential components required for vector database integration.\n",
    "\n",
    "### Production-Ready Implementation Available\n",
    "\n",
    "The OpenSearch operator demonstrated in this tutorial has been fully implemented and is available for immediate use in your NV-Ingest projects. You can find the complete, production-ready implementation at:\n",
    "\n",
    "**`client/src/nv_ingest_client/util/vdb/opensearch.py`**\n",
    "\n",
    "This implementation includes all the features covered in this tutorial:\n",
    "\n",
    "- ✅ Complete OpenSearch integration with k-NN vector search\n",
    "- ✅ Configurable connection parameters and index settings\n",
    "- ✅ Robust data validation and content filtering\n",
    "- ✅ Efficient batch processing and error handling\n",
    "- ✅ NVIDIA embedding model integration for query vectorization\n",
    "- ✅ Optimized response formatting and payload management\n",
    "\n",
    "### Getting Started with the OpenSearch Operator\n",
    "\n",
    "To use the pre-built OpenSearch operator in your NV-Ingest pipeline:\n",
    "\n",
    "```python\n",
    "from nv_ingest_client.util.vdb.opensearch import OpenSearch\n",
    "\n",
    "# Initialize the operator with your configuration\n",
    "opensearch_vdb = OpenSearch(\n",
    "    host=\"localhost\",\n",
    "    port=9200,\n",
    "    index_name=\"my_custom_index\",\n",
    "    dense_dim=2048\n",
    ")\n",
    "\n",
    "# Use in your NV-Ingest pipeline\n",
    "ingestor = ingestor.vdb_upload(vdb_op=opensearch_vdb)\n",
    "```\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Explore the Implementation**: Review the complete source code in `opensearch.py` to understand advanced features and optimizations\n",
    "2. **Customize for Your Needs**: Modify the operator parameters to match your specific requirements\n",
    "3. **Deploy in Production**: Integrate the operator into your NV-Ingest pipeline for production use\n",
    "4. **Build Your Own**: Use this tutorial as a template to create operators for other vector databases\n",
    "\n",
    "For additional support and advanced usage patterns, refer to the [NV-Ingest documentation](https://github.com/NVIDIA/nv-ingest) and the OpenSearch operator source code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
