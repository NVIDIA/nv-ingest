{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c031327-2456-41a2-b0ef-975bf96823c7",
   "metadata": {},
   "source": [
    "## How to add metadata to your documents and filter searches\n",
    "This notebook will walk you through how to upload metadata that provides extra information about the corpus you are ingesting with nv-ingest. It will show the requirements for the metadata file and what file types are supported. Then we will go throught he process of filtering searches, in this case, on the metadata we provided.\n",
    "\n",
    "First step is to provide imports for all the tools we will be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d32ff2e-ab3c-4118-9d74-ef3c63837003",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/nv_ingest_runtime/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from nv_ingest_client.client import Ingestor\n",
    "from nv_ingest_client.util.milvus import nvingest_retrieval\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18ab4bf-6a00-4008-aa10-87741369fad1",
   "metadata": {},
   "source": [
    "Next we will annotate all the necessary variables to ensure our client connects to our pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a902bd2d-cf8e-4b68-8a98-a5b535e440d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"nvidia/llama-3.2-nv-embedqa-1b-v2\"\n",
    "hostname=\"localhost\"\n",
    "collection_name = \"nv_ingest_collection\"\n",
    "sparse = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dde8506-44c7-4536-96c8-4cc1d273ba46",
   "metadata": {},
   "source": [
    "Now, we will begin by creating a dataframe with dummy metadata in it. The metadata can be ingested as either a dataframe or a file. Supported file types (json, csv, parquet). If you supply a file it will be converted into a pandas dataframe for you. In this example, after we create the dataframe, we write it to a file and we will use that file as part of the ingestion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f6b451d-40d8-46d8-88c5-aac7facd278d",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df = pd.DataFrame(\n",
    "    {\n",
    "        \"source\": [\"data/woods_frost.pdf\", \"data/multimodal_test.pdf\"],\n",
    "        \"meta_a\": [\"alpha\", \"bravo\"]\n",
    "    }\n",
    ")\n",
    "file_path = \"./meta_df.csv\"\n",
    "meta_df.to_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157d8909-542b-47fd-b01c-6689eefdaf11",
   "metadata": {},
   "source": [
    "If you are supplying metadata during ingestion you are required to supply three keyword arguments.\n",
    "\n",
    "- meta_dataframe - This is either a string representing the file (to be loaded via pandas) or the already loaded dataframe.\n",
    "- meta_source_field - This is a string, that represents the field that will be used to connect to the document during ingestion.\n",
    "- meta_fields - This is a list of strings, representing the columns of data from the dataframe that will be used as metadata for the corresponding documents.\n",
    "\n",
    "All three of the parameters are required to enable metadata updates to the documents during ingestion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6f9e2a4-7e50-491d-a0c6-21a4d4f27db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'text' parameter is deprecated and will be ignored. Future versions will remove this argument.\n",
      "'tables' parameter is deprecated and will be ignored. Future versions will remove this argument.\n"
     ]
    }
   ],
   "source": [
    "ingestor = ( \n",
    "    Ingestor(message_client_hostname=hostname)\n",
    "    .files([\"data/woods_frost.pdf\", \"data/multimodal_test.pdf\"])\n",
    "    .extract(\n",
    "        extract_text=True,\n",
    "        extract_tables=True,\n",
    "        extract_charts=True,\n",
    "        extract_images=True,\n",
    "        text_depth=\"page\"\n",
    "    ).embed(text=True, tables=True\n",
    "    ).vdb_upload(collection_name=collection_name, milvus_uri=f\"http://{hostname}:19530\", sparse=sparse, minio_endpoint=f\"{hostname}:9000\", dense_dim=2048\n",
    "                 ,meta_dataframe=file_path, meta_source_field=\"source\", meta_fields=[\"meta_a\"]\n",
    "                )\n",
    ")\n",
    "results = ingestor.ingest_async().result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b722d073-5a87-4109-acc7-9c1d4399b625",
   "metadata": {},
   "source": [
    "Once the ingestion is complete, the documents will have uploaded to the vector database with the corresponding metadata as part of the `content_metadata` field. This is a json field that can be used as part of a filtered search. To use this, you can select a column from the meta_fields previously described and filter based on a value for that sub-field. That is what is done in this example below. There are more extensive filters that can be applied, please refer to https://milvus.io/docs/use-json-fields.md#Query-with-filter-expressions for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1396906e-321a-4ab6-af83-9e651a51cb7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /opt/conda/envs/nv_ingest_runtime/lib/python3.12/site-\n",
      "[nltk_data]     packages/llama_index/core/_static/nltk_cache...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[data: [[{'id': 458710425561758215, 'distance': 0.016393441706895828, 'entity': {'source': {'source_name': '/raid/nv-ingest/data/woods_frost.pdf', 'source_id': '/raid/nv-ingest/data/woods_frost.pdf', 'source_location': '', 'source_type': 'PDF', 'collection_id': '', 'date_created': '2024-04-30T18:02:30', 'last_modified': '2024-04-30T18:02:32', 'summary': '', 'partition_id': -1, 'access_level': -1}, 'content_metadata': {'type': 'text', 'description': 'Unstructured text from PDF document.', 'page_number': 0, 'hierarchy': {'page_count': 2, 'page': 0, 'block': -1, 'line': -1, 'span': -1, 'nearby_objects': {'text': {'content': [], 'bbox': [], 'type': []}, 'images': {'content': [], 'bbox': [], 'type': []}, 'structured': {'content': [], 'bbox': [], 'type': []}}}, 'subtype': '', 'start_time': -1, 'end_time': -1, 'location': None, 'max_dimensions': None, 'meta_a': 'alpha'}, 'text': 'Stopping by Woods on a Snowy Evening, By Robert Frost\\r\\nFigure 1: Snowy Woods\\r\\nWhose woods these are I think I know. His house is in the village though; He will not see me \\r\\nstopping here; To watch his woods fill up with snow. \\r\\nMy little horse must think it queer; To stop without a farmhouse near; Between the woods and \\r\\nfrozen lake; The darkest evening of the year. \\r\\nHe gives his harness bells a shake; To ask if there is some mistake. The only other sound’s the \\r\\nsweep; Of easy wind and downy flake. \\r\\nThe woods are lovely, dark and deep, But I have promises to keep, And miles to go before I \\r\\nsleep, And miles to go before I sleep.\\r\\nFrost’s Collections\\r\\nFigure 2: Robert Frost'}}, {'id': 458710425561758217, 'distance': 0.016129031777381897, 'entity': {'source': {'source_name': '/raid/nv-ingest/data/woods_frost.pdf', 'source_id': '/raid/nv-ingest/data/woods_frost.pdf', 'source_location': '', 'source_type': 'PDF', 'collection_id': '', 'date_created': '2024-04-30T18:02:30', 'last_modified': '2024-04-30T18:02:32', 'summary': '', 'partition_id': -1, 'access_level': -1}, 'content_metadata': {'type': 'text', 'description': 'Unstructured text from PDF document.', 'page_number': 1, 'hierarchy': {'page_count': 2, 'page': 1, 'block': -1, 'line': -1, 'span': -1, 'nearby_objects': {'text': {'content': [], 'bbox': [], 'type': []}, 'images': {'content': [], 'bbox': [], 'type': []}, 'structured': {'content': [], 'bbox': [], 'type': []}}}, 'subtype': '', 'start_time': -1, 'end_time': -1, 'location': None, 'max_dimensions': None, 'meta_a': 'alpha'}, 'text': \"# Collection Year 1 A Boy's Will 1913 2 North of Boston 1914 3 Mountain Interval 1916 4 New Hampshire 1923 5 West Running Brook 1928 6 A Further Range 1937 7 A Witness Tree 1942 8 In the Clearing 1962 9 Steeple Bush 1947\\r\\n10 An Afterwordunknown\"}}, {'id': 458710425561758219, 'distance': 0.01587301678955555, 'entity': {'source': {'source_name': '/raid/nv-ingest/data/woods_frost.pdf', 'source_id': '/raid/nv-ingest/data/woods_frost.pdf', 'source_location': '', 'source_type': 'PDF', 'collection_id': '', 'date_created': '2024-04-30T18:02:30', 'last_modified': '2024-04-30T18:02:32', 'summary': '', 'partition_id': -1, 'access_level': -1}, 'content_metadata': {'type': 'structured', 'description': 'Structured table extracted from PDF document.', 'page_number': 1, 'hierarchy': {'page_count': 2, 'page': 1, 'block': -1, 'line': -1, 'span': -1, 'nearby_objects': {'text': {'content': [], 'bbox': [], 'type': []}, 'images': {'content': [], 'bbox': [], 'type': []}, 'structured': {'content': [], 'bbox': [], 'type': []}}}, 'subtype': 'table', 'start_time': -1, 'end_time': -1, 'location': [89, 29, 697, 379], 'max_dimensions': [792, 1024], 'meta_a': 'alpha'}, 'text': \"| # | Collection | Year |\\n| 1 | A Boy's Will | 1913 |\\n| 2 | North of Boston | 1914 |\\n| 3 | Mountain Interval | 1916 |\\n| 4 | New Hampshire | 1923 |\\n| 5 | West Running Brook | 1928 |\\n| 6 | A Further Range | 1937 |\\n| 7 | A Witness Tree | 1942 |\\n| 8 | In the Clearing | 1962 |\\n| 9 | Steeple Bush | 1947 |\\n| 10 | An Afterword | unknown |\\n\"}}]]]\n"
     ]
    }
   ],
   "source": [
    "queries = [\"this is expensive\"]\n",
    "top_k = 5\n",
    "q_results = []\n",
    "for que in queries:\n",
    "    q_results.append(nvingest_retrieval([que], collection_name=collection_name, host=f\"http://{hostname}:19530\", embedding_endpoint=f\"http://{hostname}:8012/v1\",  hybrid=sparse, top_k=top_k, model_name=model_name, gpu_search=False\n",
    "                                            , _filter='content_metadata[\"meta_a\"] == \"alpha\"'\n",
    "                                           ))\n",
    "\n",
    "print(f\"{q_results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f111bc-ba01-406d-98fe-e43448ccc531",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
