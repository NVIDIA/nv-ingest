{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "056ce677",
   "metadata": {},
   "source": [
    "# NV-Ingest: Python Client Quick Start Guide\n",
    "\n",
    "This notebook provides a quick start guide to using the NV-Ingest Python API to create a client that interacts with a running NV-Ingest cluster. It will walk through the following:\n",
    "\n",
    "- Define the task configuration for an NV-Ingest job\n",
    "- Submit a job to the NV-Ingest cluster and retrieve completed results\n",
    "- Investigate the multimodal extractions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14fe242",
   "metadata": {},
   "source": [
    "Specify a few parameters to connect to our nv-ingest cluster and a notional document to guide the examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7727953",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# client config\n",
    "HTTP_HOST = os.environ.get('HTTP_HOST', \"localhost\")\n",
    "HTTP_PORT = os.environ.get('HTTP_PORT', \"7670\")\n",
    "TASK_QUEUE = os.environ.get('TASK_QUEUE', \"morpheus_task_queue\")\n",
    "\n",
    "# minio config\n",
    "MINIO_ACCESS_KEY = os.environ.get('MINIO_ACCESS_KEY', \"minioadmin\")\n",
    "MINIO_SECRET_KEY = os.environ.get('MINIO_SECRET_KEY', \"minioadmin\")\n",
    "\n",
    "# time to wait for job to complete\n",
    "DEFAULT_JOB_TIMEOUT = 90\n",
    "\n",
    "# sample input file and output directory\n",
    "SAMPLE_PDF = \"/workspace/nv-ingest/data/multimodal_test.pdf\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61db5566",
   "metadata": {},
   "source": [
    "## The NV-Ingest Python Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccddd853",
   "metadata": {},
   "outputs": [],
   "source": [
    "from base64 import b64decode\n",
    "import time\n",
    "\n",
    "from nv_ingest_client.client import Ingestor\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69045f8a",
   "metadata": {},
   "source": [
    "Each ingest job includes a set of tasks. These tasks define the operations that will be performed during ingestion. This allows each job to potentially have different ingestion instructions. Here we define a simple extract oriented job, but the full list of supported options are contained below:\n",
    "\n",
    "- `extract` : Performs multimodal extractions from a document, including text, images, and tables.\n",
    "- `split` : Chunk the text into smaller chunks, useful for storing in a vector database for retrieval applications.\n",
    "- `dedup` : Identifies duplicate images in document that can be filtered to remove data redundancy.\n",
    "- `filter` : Filters out images that are likely not useful using some heuristics, including size and aspect ratio.\n",
    "- `embed` : Computes an embedding for the extracted content using a [`nvidia/llama-3.2-nv-embedqa-1b-v2`](https://catalog.ngc.nvidia.com/orgs/nim/teams/nvidia/containers/llama-3.2-nv-embedqa-1b-v2) NVIDIA Inference Microservice (NIM) by default.\n",
    "- `vbd_upload` : Save embeddings, chunks, and metadata to a Milvus vector database.\n",
    "\n",
    "We'll use the Ingestor interface to chain together an extraction tast and a deduplication task to ingest our sample PDF. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f654ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_PDF = \"../../../data/multimodal_test.pdf\"\n",
    "\n",
    "ingestor = (\n",
    "    Ingestor(message_client_hostname=HTTP_HOST)\n",
    "    .files(SAMPLE_PDF)\n",
    "    .extract(\n",
    "        extract_text=True,\n",
    "        extract_tables=True,\n",
    "        extract_charts=True,\n",
    "        extract_images=True,\n",
    "        text_depth=\"document\",\n",
    "    ).dedup(\n",
    "        content_type=\"image\",\n",
    "        filter=True,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1875df4a",
   "metadata": {},
   "source": [
    "Submit the job to our NV-Ingest cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119c7db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_metadata = ingestor.ingest()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a833d21b",
   "metadata": {},
   "source": [
    "## Explore the Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5078539",
   "metadata": {},
   "source": [
    "Let's explore elements of the NV-Ingest output. When data flows through an NV-Ingest pipeline, a number of extractions and transformations are performed. As the data is enriched, it is stored in rich metadata hierarchy. In the end, there will be a list of dictionaries, each of which represents a extracted type of information. The most common elements to extract from a dictionary in this hierarchy are the extracted content and the text representation of this content. The next few cells will demonstrate interacting with the metadata, pulling out these elements, and visualizing them. Note, when there is a `-1` value present, this represents non-applicable positional resolution. Positive numbers represent valid positional data.\n",
    "\n",
    "For a more complete description of metadata elements, view the data dictionary.\n",
    "\n",
    "[https://github.com/NVIDIA/nv-ingest/blob/main/docs/content-metadata.md](https://github.com/NVIDIA/nv-ingest/blob/main/docs/content-metadata.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94023458",
   "metadata": {},
   "outputs": [],
   "source": [
    "def redact_metadata_helper(metadata: dict) -> dict:\n",
    "    \"\"\"A simple helper function to redact `metadata[\"content\"]` so improve readability.\"\"\"\n",
    "    \n",
    "    text_metadata_redact = text_metadata.copy()\n",
    "    text_metadata_redact[\"content\"] = \"<---Redacted for readability--->\"\n",
    "    \n",
    "    return text_metadata_redact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32838272",
   "metadata": {},
   "source": [
    "### Explore Output - Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99f8635",
   "metadata": {},
   "source": [
    "This cell depicts the full metadata hierarchy for a text extraction with redacted content to ease readability. Notice the following sections are populated with information:\n",
    "\n",
    "- `content` - The raw extracted content, text in this case - this section will always be populated with a successful job.\n",
    "- `content_metadata` - Describes the type of extraction and its position in the broader document - this section will always be populated with a successful job.\n",
    "- `source_metadata` - Describes the source document that is the basis of the ingest job.\n",
    "- `text_metadata` - Contain information about the text extraction, including detected language, among others - this section will only exist when `metadata['content_metadata']['type'] == 'text'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c0dca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_metadata = generated_metadata[3][\"metadata\"]\n",
    "redact_metadata_helper(text_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa81e550",
   "metadata": {},
   "source": [
    "View the text extracted from the sample document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c52623",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_metadata[\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f2f01e",
   "metadata": {},
   "source": [
    "### Explore Output - Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a180bca",
   "metadata": {},
   "source": [
    "This cell depicts the full metadata hierarchy for a table extraction with redacted content to ease readability. Notice the following sections are populated with information:\n",
    "\n",
    "- `content` - The raw extracted content, a base64 encoded image of the extracted table in this case - this section will always be populated with a successful job.\n",
    "- `content_metadata` - Describes the type of extraction and its position in the broader document - this section will always be populated with a successful job.\n",
    "- `source_metadata` - Describes the source and storage path of an extracted table in an S3 compliant object store.\n",
    "- `table_metadata` - Contains the text representation of the table, positional data, and other useful elements - this section will only exist when `metadata['content_metadata']['type'] == 'structured'`.\n",
    "\n",
    "Note, `table_metadata` will store chart and table extractions. The are distringuished by `metadata['content_metadata']['subtype']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e44456",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_metadata = generated_metadata[4][\"metadata\"]\n",
    "redact_metadata_helper(table_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3ec129",
   "metadata": {},
   "source": [
    "Visualize the table contained within the extracted metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e59c952",
   "metadata": {},
   "outputs": [],
   "source": [
    "display.Image(b64decode(table_metadata[\"content\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17eb3f8a",
   "metadata": {},
   "source": [
    "View the corresponding text that maps to this table. This text could be embedded to support multimodal retrieval workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adb8706",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_metadata[\"table_metadata\"][\"table_content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36cbf7c",
   "metadata": {},
   "source": [
    "### Explore Output - Charts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77f6680",
   "metadata": {},
   "source": [
    "This cell depicts the full metadata hierarchy for a chart extraction with redacted content to ease readability. Notice the following sections are populated with information:\n",
    "\n",
    "- `content` - The raw extracted content, a base64 encoded image of the extracted chart in this case - this section will always be populated with a successful job.\n",
    "- `content_metadata` - Describes the type of extraction and its position in the broader document - this section will always be populated with a successful job.\n",
    "- `source_metadata` - Describes the source and storage path of an extracted chart in an S3 compliant object store.\n",
    "- `table_metadata` - Contains the text representation of the chart, positional data, and other useful elements - this section will only exist when `metadata['content_metadata']['type'] == 'structured'`.\n",
    "\n",
    "Note, `table_metadata` will store chart and table extractions. The are distringuished by `metadata['content_metadata']['subtype']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc886cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "chart_metadata = generated_metadata[7][\"metadata\"]\n",
    "chart_metadata_redact = chart_metadata.copy()\n",
    "chart_metadata_redact[\"content\"] = \"<---Redacted for readability--->\"\n",
    "chart_metadata_redact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f07d604",
   "metadata": {},
   "source": [
    "Visualize the chart contained within the extracted metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40efa3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "display.Image(b64decode(chart_metadata[\"content\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57372b0",
   "metadata": {},
   "source": [
    "View the corresponding text that maps to this chart. This text could be embedded to support multimodal retrieval workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb73ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "chart_metadata[\"table_metadata\"][\"table_content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa166f0",
   "metadata": {},
   "source": [
    "### Explore Output - Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa873466",
   "metadata": {},
   "source": [
    "This cell depicts the full metadata hierarchy for a image extraction with redacted content to ease readability. Notice the following sections are populated with information:\n",
    "\n",
    "- `content` - The raw extracted content, a base64 encoded image extracted from the document in this case - this section will always be populated with a successful job.\n",
    "- `content_metadata` - Describes the type of extraction and its position in the broader document - this section will always be populated with a successful job.\n",
    "- `source_metadata` - Describes the source and storage path of an extracted image in an S3 compliant object store.\n",
    "- `image_metadata` - Contains the image type, positional data, and other useful elements - this section will only exist when `metadata['content_metadata']['type'] == 'image'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9e6ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_metadata = generated_metadata[1][\"metadata\"]\n",
    "redact_metadata_helper(img_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7658af1",
   "metadata": {},
   "source": [
    "Visualize the image contained within the extracted metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd39c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "display.Image(b64decode(img_metadata[\"content\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf13b36-bc78-4f6c-81a3-5a0f901fdf09",
   "metadata": {},
   "source": [
    "### Optional:  Expanded Task Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29ebd0d",
   "metadata": {},
   "source": [
    "This section illustrates usage of the remaining task types used when supporting retrieval workflows.\n",
    "\n",
    "- `filter` : Filters out images that are likely not useful using some heuristics, including size and aspect ratio.\n",
    "- `split` : Chunk the text into smaller chunks, useful for storing in a vector database for retrieval applications.\n",
    "- `embed` - Computes an embedding for the extracted content using a [nvidia/llama-3.2-nv-embedqa-1b-v2`](https://catalog.ngc.nvidia.com/orgs/nim/teams/nvidia/containers/llama-3.2-nv-embedqa-1b-v2) NVIDIA Inference Microservice (NIM) by default.\n",
    "- `vdb_upload` - Inserts ingested content into a Milvus vector database to support retrieval use cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856422c5",
   "metadata": {},
   "source": [
    "Define the ingest job specification. Here the task configuration is expanded, but requires the ancillary services (Embedding NIM, MinIO object stor, and Milvus Vector Database) to be up and running to return metadata back to the client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110b7467",
   "metadata": {},
   "outputs": [],
   "source": [
    "ingestor = (\n",
    "    Ingestor(message_client_hostname=HTTP_HOST)\n",
    "    .files(SAMPLE_PDF)\n",
    "    .extract(\n",
    "        extract_text=True,\n",
    "        extract_tables=True,\n",
    "        extract_charts=True,\n",
    "        extract_images=True,\n",
    "        text_depth=\"document\",\n",
    "    ).dedup(\n",
    "        content_type=\"image\",\n",
    "        filter=True,\n",
    "    ).filter(\n",
    "        content_type=\"image\",\n",
    "        min_size=128,\n",
    "        max_aspect_ratio=5.0,\n",
    "        min_aspect_ratio=0.2,\n",
    "        filter=True,\n",
    "    ).split(\n",
    "        chunk_size=300,\n",
    "        chunk_overlap=10,\n",
    "        params={\n",
    "            \"split_source_types\": [\"PDF\"],\n",
    "        },\n",
    "    )\n",
    "    .embed()\n",
    "    .vdb_upload(dense_dim=2048)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d1db56",
   "metadata": {},
   "source": [
    "Submit the job and retrieve the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30e87de",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_metadata = ingestor.ingest()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8999e2-acbd-48e6-a30f-4cea5e745152",
   "metadata": {},
   "source": [
    "Query the Milvus VDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d2ea9a-dc2e-4570-bde9-5a5317a66ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nv_ingest_client.util.milvus import nvingest_retrieval\n",
    "\n",
    "query = \"What is the dog doing and where?\"\n",
    "\n",
    "nvingest_retrieval(\n",
    "        [query],\n",
    "        \"nv_ingest_collection\",\n",
    "        hybrid=False,\n",
    "        embedding_endpoint=\"http://localhost:8012/v1\",\n",
    "        model_name=\"nvidia/llama-3.2-nv-embedqa-1b-v2\",\n",
    "        top_k=1,\n",
    "        gpu_search=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eada27cb-d7b6-4e47-a09a-483ea9d758fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
