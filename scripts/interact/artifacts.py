"""
Pydantic models for nv-ingest test artifacts.

These models define the structure of JSON files generated by the testing framework,
making it easier to understand, parse, and validate test outputs.
"""

from datetime import datetime
from typing import Dict, Any, Optional
from pydantic import BaseModel, Field, field_validator


class TestSummary(BaseModel):
    """
    Model for the summary.json file generated by run.py.

    This file contains high-level test execution metadata.
    """

    case: str = Field(..., description="Name of the test case that was executed")
    infra: str = Field(..., description="Infrastructure mode used (managed/attach)")
    profiles: str = Field(..., description="Docker compose profiles used")
    stdout: str = Field(..., description="Filename of the stdout capture file")
    return_code: int = Field(..., description="Exit code of the test execution")

    @field_validator("infra")
    @classmethod
    def validate_infra(cls, v):
        if v not in ["managed", "attach"]:
            raise ValueError('infra must be either "managed" or "attach"')
        return v

    @field_validator("return_code")
    @classmethod
    def validate_return_code(cls, v):
        if v < 0:
            raise ValueError("return_code must be non-negative")
        return v


class DC20E2EResults(BaseModel):
    """
    Model for dc20_e2e.json test results.

    This captures the specific metrics from the DC20 end-to-end test case.
    """

    result_count: Optional[int] = Field(None, description="Number of results processed")
    failure_count: Optional[int] = Field(None, description="Number of failures encountered")
    ingestion_time_s: Optional[float] = Field(None, description="Time spent on ingestion in seconds")
    text_chunks: Optional[int] = Field(None, description="Number of text chunks extracted")
    table_chunks: Optional[int] = Field(None, description="Number of table chunks extracted")
    chart_chunks: Optional[int] = Field(None, description="Number of chart chunks extracted")
    image_chunks: Optional[int] = Field(None, description="Number of image chunks extracted")
    infographic_chunks: Optional[int] = Field(None, description="Number of infographic chunks extracted")
    retrieval_time_s: Optional[float] = Field(None, description="Time spent on retrieval in seconds")

    @field_validator(
        "result_count",
        "failure_count",
        "text_chunks",
        "table_chunks",
        "chart_chunks",
        "image_chunks",
        "infographic_chunks",
    )
    @classmethod
    def validate_counts(cls, v):
        """Ensure count fields are non-negative."""
        if v is not None and v < 0:
            raise ValueError("Count fields must be non-negative")
        return v

    @field_validator("ingestion_time_s", "retrieval_time_s")
    @classmethod
    def validate_times(cls, v):
        """Ensure time fields are non-negative."""
        if v is not None and v < 0:
            raise ValueError("Time fields must be non-negative")
        return v


class TestArtifacts(BaseModel):
    """
    Model representing the complete set of test artifacts in a directory.

    This provides a structured way to access all test outputs.
    """

    timestamp: str = Field(..., description="Timestamp directory name (YYYYMMDD_HHMMSS)")
    summary: TestSummary = Field(..., description="Test execution summary")
    stdout_content: Optional[str] = Field(None, description="Content of stdout.txt file")
    test_results: Optional[Dict[str, Any]] = Field(None, description="Test-specific results (e.g., dc20_e2e.json)")

    @field_validator("timestamp")
    @classmethod
    def validate_timestamp_format(cls, v):
        """Validate timestamp follows expected format."""
        try:
            datetime.strptime(v, "%Y%m%d_%H%M%S")
        except ValueError:
            raise ValueError("timestamp must be in format YYYYMMDD_HHMMSS")
        return v


def load_test_artifacts(artifacts_dir: str) -> TestArtifacts:
    """
    Load and parse all test artifacts from a directory.

    Args:
        artifacts_dir: Path to the artifacts directory

    Returns:
        TestArtifacts object with parsed data

    Raises:
        FileNotFoundError: If required files are missing
        ValidationError: If data doesn't match expected schema
    """
    import json
    import os

    # Extract timestamp from directory name
    timestamp = os.path.basename(artifacts_dir)

    # Load summary.json
    summary_path = os.path.join(artifacts_dir, "summary.json")
    with open(summary_path, "r") as f:
        summary_data = json.load(f)
    summary = TestSummary(**summary_data)

    # Load stdout.txt if it exists
    stdout_path = os.path.join(artifacts_dir, "stdout.txt")
    stdout_content = None
    if os.path.exists(stdout_path):
        with open(stdout_path, "r") as f:
            stdout_content = f.read()

    # Load test-specific results
    test_results = {}
    for filename in os.listdir(artifacts_dir):
        if filename.endswith(".json") and filename != "summary.json":
            filepath = os.path.join(artifacts_dir, filename)
            with open(filepath, "r") as f:
                content = f.read()

            # Parse as JSON
            test_results[filename] = json.loads(content)

    return TestArtifacts(timestamp=timestamp, summary=summary, stdout_content=stdout_content, test_results=test_results)


# Example usage and validation functions
def validate_dc20_results(results_dict: Dict[str, Any]) -> DC20E2EResults:
    """
    Validate and parse DC20 E2E test results.

    Args:
        results_dict: Dictionary of results from dc20_e2e.json

    Returns:
        Validated DC20E2EResults object
    """
    return DC20E2EResults(**results_dict)


if __name__ == "__main__":
    # Example usage
    print("Pydantic models for nv-ingest test artifacts")
    print("Use these models to parse and validate test outputs:")
    print()
    print("# Load artifacts from a directory")
    print("artifacts = load_test_artifacts('/path/to/artifacts/20240813_171507')")
    print()
    print("# Access structured data")
    print("print(f'Test case: {artifacts.summary.case}')")
    print("print(f'Return code: {artifacts.summary.return_code}')")
    print()
    print("# Parse specific test results")
    print("if 'dc20_e2e.json' in artifacts.test_results:")
    print("    events = artifacts.test_results['dc20_e2e.json']")
    print("    for event in events:")
    print("        print(f'{event['metric_name']}: {event['value']}')")
