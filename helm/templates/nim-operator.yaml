
# ---
# apiVersion: apps.nvidia.com/v1alpha1
# kind: NIMCache
# metadata:
#   name: llama-3.1-nemotron-nano-vl-8b-v1
# spec:
#   source:
#     ngc:
#       modelPuller: nvcr.io/nim/nvidia/llama-3.1-nemotron-nano-vl-8b-v1:latest
#       pullSecret: ngc-secret
#       authSecret: ngc-api-secret
#   storage:
#     pvc:
#       create: true
#       storageClass: {{ .Values.nimOperator.nimCache.pvc.storageClass | default "" }}
#       size: "300Gi"
#       volumeAccessMode: ReadWriteMany
#   resources: {}
---
apiVersion: apps.nvidia.com/v1alpha1
kind: NIMCache
metadata:
  name: llama-3.2-nv-rerankqa-1b-v2
spec:
  source:
    ngc:
      modelPuller: nvcr.io/nim/nvidia/llama-3.2-nv-rerankqa-1b-v2:1.8.0
      pullSecret: ngc-secret
      authSecret: ngc-api-secret
  storage:
    pvc:
      create: true
      # You should use the appropriate storage class for your cluster
      storageClass: {{ .Values.nimOperator.nimCache.pvc.storageClass | default "standard" }}
      size: "50Gi"
      volumeAccessMode: ReadWriteMany
  resources: {}
---
apiVersion: apps.nvidia.com/v1alpha1
kind: NIMCache
metadata:
  name: nemoretriever-ocr-v1
spec:
  source:
    ngc:
      # modelPuller: nvcr.io/nvstaging/nim/nemoretriever-ocr-v1:1.2.0-rc2-latest-release-37212681
      modelPuller: nvcr.io/nvstaging/nim/nemoretriever-ocr-v1:1.2.0-rc2-latest-release-37831672
      # modelPuller: nvcr.io/nvidia/nemo-microservices/nemoretriever-ocr-v1:1.1.0
      pullSecret: ngc-secret
      authSecret: ngc-api-secret
  storage:
    pvc:
      create: true
      # You should use the appropriate storage class for your cluster
      storageClass: {{ .Values.nimOperator.nimCache.pvc.storageClass | default "standard" }}
      size: "25Gi"
      volumeAccessMode: ReadWriteMany
  resources: {}
---
# ---
# apiVersion: apps.nvidia.com/v1alpha1
# kind: NIMCache
# metadata:
#   name: paddleocr
# spec:
#   source:
#     ngc:
#       modelPuller: nvcr.io/nim/baidu/paddleocr:1.5.0
#       pullSecret: ngc-secret
#       authSecret: ngc-api-secret
#   storage:
#     pvc:
#       create: true
#       # You should use the storage class that is available in your cluster
#       storageClass: {{ .Values.nimOperator.nimCache.pvc.storageClass | default "standard" }}
#       size: "25Gi"
#       volumeAccessMode: ReadWriteMany
#   resources: {}
---
# apiVersion: apps.nvidia.com/v1alpha1
# kind: NIMService
# metadata:
#   name: llama-31-nemotron-nano-vl-8b-v1
# spec:
#   image:
#     repository: nvcr.io/nim/nvidia/llama-3.1-nemotron-nano-vl-8b-v1
#     tag: latest
#     pullPolicy: IfNotPresent
#     pullSecrets:
#       - ngc-secret
#   authSecret: ngc-api-secret
#   storage:
#     nimCache:
#       name: llama-3.1-nemotron-nano-vl-8b-v1
#       profile: ''
#   replicas: 1
#   resources:
#     limits:
#       nvidia.com/gpu: 1
#   expose:
#     service:
#       type: ClusterIP
#       port: 8000
---
apiVersion: apps.nvidia.com/v1alpha1
kind: NIMService
metadata:
  name: llama-32-nv-rerankqa-1b-v2
spec:
  image:
    repository:  nvcr.io/nim/nvidia/llama-3.2-nv-rerankqa-1b-v2
    tag: 1.8.0
    pullPolicy: IfNotPresent
    pullSecrets:
      - ngc-secret
  authSecret: ngc-api-secret
  storage:
    nimCache:
      name: llama-3.2-nv-rerankqa-1b-v2
      profile: ''
  replicas: 1
  nodeSelector:
    nvidia.com/mig.config: all-1g.23gb
  resources:
    limits:
      nvidia.com/gpu: 1
  tolerations:
    - key: "nvidia.com/mig"
      operator: "Equal"
      value: "true"
      effect: "NoSchedule"
    - key: nvidia.com/gpu
      operator: Exists
      effect: NoSchedule
  expose:
    service:
      type: ClusterIP
      port: 8000
---
apiVersion: apps.nvidia.com/v1alpha1
kind: NIMService
metadata:
  name: nemoretriever-ocr-v1
spec:
  image:
    repository: nvcr.io/nvstaging/nim/nemoretriever-ocr-v1
    # tag: 1.2.0-rc2-latest-release-37212681
    tag: 1.2.0-rc2-latest-release-37831672
    # repository: nvcr.io/nvidia/nemo-microservices/nemoretriever-ocr-v1
    # tag: 1.1.0
    pullPolicy: IfNotPresent
    pullSecrets:
      - ngc-secret
  authSecret: ngc-api-secret
  storage:
    nimCache:
      name: nemoretriever-ocr-v1
      profile: ''
  replicas: 1
  nodeSelector:
    nvidia.com/mig.config: all-1g.23gb
  resources:
    limits:
      nvidia.com/gpu: 1
  tolerations:
    - key: "nvidia.com/mig"
      operator: "Equal"
      value: "true"
      effect: "NoSchedule"
    - key: nvidia.com/gpu
      operator: Exists
      effect: NoSchedule
  expose:
    service:
      type: ClusterIP
      port: 8000
      grpcPort: 8001
  env:
    - name: OMP_NUM_THREADS
      value: "8"
    - name: NIM_HTTP_API_PORT
      value: "8000"
    - name: NIM_TRITON_LOG_VERBOSE
      value: "1"
    # - name: NIM_TRITON_CUDA_MEMORY_POOL_MB
    #   value: "8192"
    - name: NIM_TRITON_MAX_BATCH_SIZE
      value: "32"
    - name: NIM_TRITON_ENABLE_MODEL_CONTROL
      value: "1"
---
# apiVersion: apps.nvidia.com/v1alpha1
# kind: NIMService
# metadata:
#   name: paddleocr
# spec:
#   image:
#     repository: nvcr.io/nim/baidu/paddleocr
#     tag: 1.5.0
#     pullPolicy: IfNotPresent
#     pullSecrets:
#       - ngc-secret
#   authSecret: ngc-api-secret
#   storage:
#     nimCache:
#       name: paddleocr
#       profile: ''
#   replicas: 1
#   resources:
#     limits:
#       nvidia.com/gpu: 1
#   expose:
#     service:
#       type: ClusterIP
#       port: 8000
#     service:
#       grpcPort: 8001
#   env:
#     - name: NIM_TRITON_LOG_VERBOSE
#       value: "1"
#     - name: NIM_TRITON_RATE_LIMIT
#       value: "3"
#     - name: NIM_TRITON_CUDA_MEMORY_POOL_MB
#       value: "3072"
#     - name: NIM_TRITON_CPU_THREADS_PRE_PROCESSOR
#       value: "2"
#     - name: OMP_NUM_THREADS
#       value: "8"
#     - name: NIM_TRITON_CPU_THREADS_POST_PROCESSOR
#       value: "1"
