# Text embedding stage config (retriever.text_embed)
#
# This YAML is passed to:
#   retriever.text_embed.config.load_text_embedding_schema_from_dict(...)
# which validates against nv-ingest-api's `TextEmbeddingSchema`.
#
# Minimal required fields are optional (schema provides defaults), but you
# typically set api_key / endpoint / model to point at your embedding service.

# Auth (optional; can also be provided via task_config overrides)
api_key: ""  # e.g. $NGC_API_KEY or $NVIDIA_API_KEY

# Embedding service settings
# If set to null/empty, `retriever local stage5` will fall back to local HF embeddings
# via `retriever.model.local.llama_nemotron_embed_1b_v2_embedder`.
embedding_nim_endpoint: null
# embedding_nim_endpoint: "http://localhost:8012/v1"
embedding_model: "nvidia/llama-3.2-nv-embedqa-1b-v2"

# Request formatting
encoding_format: "float"   # usually "float"
input_type: "passage"      # "passage" (docs) or "query" (queries)
truncate: "END"            # how the service truncates long inputs

# Batch sizing (NIM-side batching is handled internally; this is stage batching)
batch_size: 4

# Modalities for multi-modal models (leave as "text" for text-only models)
text_elements_modality: "text"
image_elements_modality: "text"
structured_elements_modality: "text"
audio_elements_modality: "text"

# Behavior
raise_on_failure: false
httpx_log_level: "WARNING"  # DEBUG | INFO | WARNING | ERROR | CRITICAL

# Optional: embed custom content from metadata.custom_content via glom path
# custom_content_field: "my_field"                 # e.g. "foo" or "nested.foo"
# result_target_field: "my_field_embedding"        # where to write embedding under custom_content

# Optional: request embedding vector size if the backend supports it
# dimensions: 1024

