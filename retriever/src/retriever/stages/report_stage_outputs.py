from __future__ import annotations

import json
import re
from collections import defaultdict
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, Iterable, List, Optional, Sequence, Tuple

import typer
from rich.console import Console
from rich.table import Table


app = typer.Typer(
    help=(
        "Report aggregated metrics from stage output JSON sidecars in a pages directory.\n\n"
        "This scans for per-page JSON outputs written by:\n"
        "  - stage2: *.page_elements_v3.json\n"
        "  - stage3: *.graphic_elements_v1.json\n"
        "  - stage4: *.table_structure_v1.json\n"
        "and estimates how many OCR crops would be generated by stage5's filter "
        "(page_element.label in {0,1,3})."
    )
)

console = Console()

_IMAGE_EXTS = (".png", ".jpg", ".jpeg")

_DOC_PAGE_RE = re.compile(r"^(?P<doc>.+)_page(?P<page>\d+)\.(?P<ext>png|jpg|jpeg)$", re.IGNORECASE)


@dataclass(frozen=True)
class PageKey:
    doc: str
    page: Optional[int]
    image_name: str


def _read_json(path: Path) -> Optional[Dict[str, Any]]:
    try:
        with path.open("r", encoding="utf-8") as f:
            obj = json.load(f)
        return obj if isinstance(obj, dict) else None
    except Exception:
        return None


def _iter_images(input_dir: Path, recursive: bool) -> List[Path]:
    it = input_dir.rglob("*") if recursive else input_dir.iterdir()
    out: List[Path] = []
    for p in it:
        if p.is_file() and p.suffix.lower() in _IMAGE_EXTS:
            out.append(p)
    return sorted(out)


def _iter_jsons(input_dir: Path, suffix: str, recursive: bool) -> List[Path]:
    pat = f"*{suffix}"
    return sorted((input_dir.rglob(pat) if recursive else input_dir.glob(pat)))


def _page_key_from_image_path(image_path: str) -> PageKey:
    name = Path(image_path).name
    m = _DOC_PAGE_RE.match(name)
    if m:
        doc = m.group("doc")
        try:
            page = int(m.group("page"))
        except Exception:
            page = None
        return PageKey(doc=doc, page=page, image_name=name)
    # Fallback: treat the image stem as a "doc" and keep page unknown
    return PageKey(doc=Path(name).stem, page=None, image_name=name)


def _get_image_path_from_stage_json(blob: Dict[str, Any]) -> Optional[str]:
    img = blob.get("image") if isinstance(blob, dict) else None
    if not isinstance(img, dict):
        return None
    p = img.get("path")
    return str(p) if p else None


def _count_ocr_eligible_detections_from_regions(regions: Sequence[Any]) -> Tuple[int, int, int]:
    """
    Returns (eligible_detections, total_detections, eligible_regions).

    Eligibility mirrors stage5 filter:
      - include a detection if its parent region's page_element.label in (0,1,3)
      - and the detection has a valid bbox_xyxy_norm_in_page
    """
    eligible = 0
    total = 0
    eligible_regions = 0

    for region in regions or []:
        if not isinstance(region, dict):
            continue

        page_el = region.get("page_element") or {}
        lab = page_el.get("label", -1)
        try:
            lab_i = int(lab)
        except Exception:
            lab_i = -1

        is_eligible_region = lab_i in (0, 1, 3)
        if is_eligible_region:
            eligible_regions += 1

        dets = region.get("detections") or []
        if not isinstance(dets, list):
            continue

        for det in dets:
            if not isinstance(det, dict):
                continue
            total += 1
            bbox = det.get("bbox_xyxy_norm_in_page")
            if not (isinstance(bbox, (list, tuple)) and len(bbox) == 4):
                continue
            if is_eligible_region:
                eligible += 1

    return eligible, total, eligible_regions


@app.command()
def run(
    input_dir: Path = typer.Option(..., "--input-dir", exists=True, file_okay=False, dir_okay=True),
    recursive: bool = typer.Option(True, "--recursive/--no-recursive", help="Scan subdirectories too."),
    top_k: int = typer.Option(25, "--top-k", min=1, help="Number of top documents to print."),
) -> None:
    """
    Print totals and top documents by OCR-eligible detections (labels 0,1,3).
    """
    images = _iter_images(input_dir, recursive=recursive)

    s2_paths = _iter_jsons(input_dir, ".page_elements_v3.json", recursive=recursive)
    s3_paths = _iter_jsons(input_dir, ".graphic_elements_v1.json", recursive=recursive)
    s4_paths = _iter_jsons(input_dir, ".table_structure_v1.json", recursive=recursive)

    # Track pages/docs primarily from images present.
    pages_by_doc: Dict[str, set] = defaultdict(set)  # doc -> set(page or image_name)
    for img in images:
        key = _page_key_from_image_path(str(img))
        pages_by_doc[key.doc].add(key.page if key.page is not None else key.image_name)

    # Also populate doc/page mapping from JSON sidecars (for runs where images aren't colocated).
    def _add_pages_from_jsons(paths: List[Path]) -> None:
        for p in paths:
            blob = _read_json(p)
            if blob is None:
                continue
            img_path = _get_image_path_from_stage_json(blob)
            if not img_path:
                continue
            key = _page_key_from_image_path(img_path)
            pages_by_doc[key.doc].add(key.page if key.page is not None else key.image_name)

    _add_pages_from_jsons(s2_paths)
    _add_pages_from_jsons(s3_paths)
    _add_pages_from_jsons(s4_paths)

    docs = sorted(pages_by_doc.keys())
    total_pdfs = len(docs)
    total_pages = sum(len(v) for v in pages_by_doc.values())

    # Stage invocation counts: per-page json outputs present (unique by image path).
    def _count_stage_invocations(paths: List[Path]) -> Tuple[int, int]:
        ok = 0
        bad = 0
        seen: set[str] = set()
        for p in paths:
            blob = _read_json(p)
            if blob is None:
                bad += 1
                continue
            img_path = _get_image_path_from_stage_json(blob)
            if not img_path:
                bad += 1
                continue
            if img_path in seen:
                continue
            seen.add(img_path)
            ok += 1
        return ok, bad

    page_elements_calls, s2_bad = _count_stage_invocations(s2_paths)
    graphic_elements_calls, s3_bad = _count_stage_invocations(s3_paths)
    table_structure_calls, s4_bad = _count_stage_invocations(s4_paths)

    # OCR estimate from stage3 + stage4 detections, filtered by parent page_element.label in (0,1,3)
    eligible_by_doc: Dict[str, int] = defaultdict(int)
    eligible_by_doc_s3: Dict[str, int] = defaultdict(int)
    eligible_by_doc_s4: Dict[str, int] = defaultdict(int)
    total_dets_by_doc_s3: Dict[str, int] = defaultdict(int)
    total_dets_by_doc_s4: Dict[str, int] = defaultdict(int)

    eligible_total = 0
    total_s3_dets = 0
    total_s4_dets = 0

    def _accum_from_stage(paths: List[Path], stage_name: str) -> Tuple[int, int, int]:
        nonlocal eligible_total, total_s3_dets, total_s4_dets

        ok = 0
        bad = 0
        missing_regions = 0

        for p in paths:
            blob = _read_json(p)
            if blob is None:
                bad += 1
                continue

            img_path = _get_image_path_from_stage_json(blob)
            if not img_path:
                bad += 1
                continue

            key = _page_key_from_image_path(img_path)

            regions = blob.get("regions")
            if not isinstance(regions, list):
                missing_regions += 1
                regions = []

            eligible, total, _eligible_regions = _count_ocr_eligible_detections_from_regions(regions)
            eligible_total += int(eligible)

            if stage_name == "stage3":
                eligible_by_doc_s3[key.doc] += int(eligible)
                total_dets_by_doc_s3[key.doc] += int(total)
                total_s3_dets += int(total)
            elif stage_name == "stage4":
                eligible_by_doc_s4[key.doc] += int(eligible)
                total_dets_by_doc_s4[key.doc] += int(total)
                total_s4_dets += int(total)

            eligible_by_doc[key.doc] += int(eligible)
            ok += 1

        return ok, bad, missing_regions

    s3_ok, s3_bad2, s3_missing_regions = _accum_from_stage(s3_paths, "stage3")
    s4_ok, s4_bad2, s4_missing_regions = _accum_from_stage(s4_paths, "stage4")

    # Avoid double-counting "bad" across stages; keep both views (parsing for invocations vs parsing for regions).
    s3_bad = max(s3_bad, s3_bad2)
    s4_bad = max(s4_bad, s4_bad2)

    # Print totals
    console.print("[bold]Stage outputs report[/bold]")
    console.print(f"input_dir={str(input_dir)} recursive={bool(recursive)}")
    console.print(f"total_pdfs={total_pdfs} total_pages={total_pages} (from image files: {len(images)})")
    console.print(
        "invocations:"
        f" page_elements(stage2)={page_elements_calls} (bad_json={s2_bad})"
        f" graphic_elements(stage3)={graphic_elements_calls} (bad_json={s3_bad})"
        f" table_structure(stage4)={table_structure_calls} (bad_json={s4_bad})"
    )
    console.print(
        "detections:"
        f" graphic_elements_total_detections={total_s3_dets}"
        f" table_structure_total_detections={total_s4_dets}"
    )
    console.print(
        "nemotron_ocr estimate (stage5 filter page_element.label in {0,1,3}): "
        f"estimated_ocr_calls={eligible_total}"
    )
    if s3_missing_regions or s4_missing_regions:
        console.print(
            f"[yellow]warning[/yellow]: missing/invalid regions arrays:"
            f" stage3={s3_missing_regions} stage4={s4_missing_regions}"
        )

    # Top-K documents
    rows = sorted(eligible_by_doc.items(), key=lambda kv: (kv[1], kv[0]), reverse=True)
    rows = rows[: int(top_k)]

    table = Table(title=f"Top {int(top_k)} documents by OCR-eligible detections", show_lines=False)
    table.add_column("rank", justify="right")
    table.add_column("document")
    table.add_column("pages", justify="right")
    table.add_column("eligible_dets", justify="right")
    table.add_column("eligible_s3", justify="right")
    table.add_column("eligible_s4", justify="right")
    table.add_column("total_s3_dets", justify="right")
    table.add_column("total_s4_dets", justify="right")

    for i, (doc, n) in enumerate(rows, start=1):
        pages = len(pages_by_doc.get(doc, set()))
        table.add_row(
            str(i),
            str(doc),
            str(pages),
            str(int(n)),
            str(int(eligible_by_doc_s3.get(doc, 0))),
            str(int(eligible_by_doc_s4.get(doc, 0))),
            str(int(total_dets_by_doc_s3.get(doc, 0))),
            str(int(total_dets_by_doc_s4.get(doc, 0))),
        )

    console.print()
    console.print(table)


def main() -> None:
    app()


if __name__ == "__main__":
    main()

